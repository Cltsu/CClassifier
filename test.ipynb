{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_conflict(data, conf_dict):\n",
    "    for conflict in data['conflicting_chunks']:\n",
    "        if 'label' in conflict:\n",
    "            conf_dict.append({\n",
    "                'A': conflict['a_contents'],\n",
    "                'B': conflict['b_contents'],\n",
    "                'base': conflict['base_contents'],\n",
    "                'label': conflict['label'] if conflict['label'] == 'A' or conflict['label'] == 'B' else  'N'\n",
    "            })\n",
    "\n",
    "\n",
    "def extract_feature(conflict):\n",
    "    return {\n",
    "        **extract_keywords(conflict),\n",
    "        **extract_edit_type(conflict),\n",
    "        **extract_exist(conflict)\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_keywords(conflict):\n",
    "    def delete_brace(text):\n",
    "        while text.find('{') == -1:\n",
    "            start_pos = text.find('{')\n",
    "            end_pos = text.find('}', start_pos)\n",
    "            if end_pos == -1:\n",
    "                break\n",
    "            text = text[0: start_pos] + (text[end_pos + 1:] if end_pos != len(text) - 1 else [])\n",
    "        return text\n",
    "\n",
    "    def get_keywords(text, nums):\n",
    "        text = delete_brace(text)\n",
    "        start_pos = {text.find(keyword) : keyword for keyword in keywords if text.find(keyword) > -1}\n",
    "        sorted_keywords = [start_pos[pos] for pos in sorted(start_pos.keys())]\n",
    "        return [labels[key] for key in (sorted_keywords + ['empty']*nums)[:nums]]\n",
    "\n",
    "    keywords = [\n",
    "        'import',\n",
    "        'private',\n",
    "        'public',\n",
    "        'protected',\n",
    "        '.',\n",
    "        '=',\n",
    "        'if',\n",
    "        'else',\n",
    "        'for',\n",
    "        'while',\n",
    "        'return',\n",
    "    ]\n",
    "    labels = {\n",
    "        'empty':0,\n",
    "        'import': 1,\n",
    "        'private': 2,\n",
    "        'public': 2,\n",
    "        'protected': 2,\n",
    "        'if': 3,\n",
    "        'else': 3,\n",
    "        'for': 4,\n",
    "        'while': 4,\n",
    "        '.': 5,\n",
    "        '=': 6,\n",
    "        'return': 7,\n",
    "    }\n",
    "    num_kw = 3\n",
    "    a_kw = get_keywords(conflict['A'], num_kw)\n",
    "    b_kw = get_keywords(conflict['B'], num_kw)\n",
    "    return {\n",
    "        'a_keyword_1': a_kw[0],\n",
    "        'a_keyword_2': a_kw[1],\n",
    "        'a_keyword_3': a_kw[1],\n",
    "        'b_keyword_1': b_kw[0],\n",
    "        'b_keyword_2': b_kw[1],\n",
    "        'b_keyword_3': a_kw[1],\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_edit_type(conflict):\n",
    "    def get_edit_type_line(cur, base):\n",
    "        cur = [line for line in str.splitlines(cur) if len(line) > 0]\n",
    "        base = [line for line in str.splitlines(base) if len(line) >0]\n",
    "        if len(cur) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return len([line for line in cur if line in base])/len(cur)\n",
    "    \n",
    "    get_edit_type = get_edit_type_line\n",
    "    return {\n",
    "        'a_edit_type': get_edit_type(conflict['A'], conflict['base']),\n",
    "        'b_edit_type': get_edit_type(conflict['B'], conflict['base']),\n",
    "        'ab_edit_type':get_edit_type(conflict['A'], conflict['B'])\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_exist(conflict):\n",
    "    return {\n",
    "        'a_exist': False if conflict['A'] == '' or conflict['A'] == '\\n' else True,\n",
    "        'b_exist': False if conflict['B'] == '' or conflict['B'] == '\\n' else True,\n",
    "        'base_exist': False if conflict['base'] == '' or conflict['base'] == '\\n' else True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6070630932439978\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def sample_normal(dataset):\n",
    "    label_set = set([sample['label'] for sample in dataset])\n",
    "    label_dict = {}\n",
    "    for label in label_set:\n",
    "        label_dict[label] = [sample for sample in dataset if sample['label'] == label]\n",
    "    min_size = min([len(samples) for (label, samples) in label_dict.items()])\n",
    "    for key in label_dict.keys():\n",
    "        random.shuffle(label_dict[key])\n",
    "    return [sample for samples in label_dict.values() for sample in samples[:min_size]]\n",
    "\n",
    "\n",
    "dataset = {}\n",
    "with open('./abm.json', 'r', encoding='utf-8') as jfile:\n",
    "    dataset = json.load(jfile)\n",
    "dataset = dataset['conf']\n",
    "dataset = sample_normal(dataset)\n",
    "random.shuffle(dataset)\n",
    "\n",
    "features = [\n",
    "    'a_keyword_1',\n",
    "    'b_keyword_1',\n",
    "    'a_keyword_2',\n",
    "    'b_keyword_2',\n",
    "    'a_exist',\n",
    "    'b_exist',\n",
    "    'base_exist',\n",
    "    'a_edit_type',\n",
    "    'b_edit_type',\n",
    "    'ab_edit_type',\n",
    "]\n",
    "train = [{key:value for (key, value) in data.items() if key in features} for data in dataset]\n",
    "vec=DictVectorizer(sparse=False)\n",
    "train = vec.fit_transform(train)\n",
    "target = [data['label'] for data in dataset]\n",
    "\n",
    "\n",
    "# train = [\n",
    "#     [\n",
    "#         data['a_keyword_1'],\n",
    "#         data['b_keyword_1'],\n",
    "#         data['a_keyword_2'],\n",
    "#         data['b_keyword_2'],\n",
    "#         data['a_exist'],\n",
    "#         data['b_exist'],\n",
    "#         data['base_exist'],\n",
    "#         data['a_edit_type'],\n",
    "#         data['b_edit_type'],\n",
    "#         data['ab_edit_type'],\n",
    "#     ] for data in dataset]\n",
    "# target = [data['label'] for data in dataset]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, target, test_size=0.2)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "# clf = RandomForestClassifier(max_depth=15, min_samples_split=5, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "print(accuracy_score(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A'], dtype='<U1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict = {\n",
    "    \"a_contents\": \"\",\n",
    "    \"b_contents\": \"\\nimport org.n52.sos.util.Constants;\\nimport org.slf4j.Logger;\\nimport org.slf4j.LoggerFactory;\\n\",\n",
    "    \"base_contents\": \"import org.n52.sos.util.Constants;\\nimport org.n52.sos.w3c.xlink.W3CHrefAttribute;\\nimport org.slf4j.Logger;\\nimport org.slf4j.LoggerFactory;\\n\",\n",
    "}\n",
    "conflict = {\n",
    "    'A': conflict['a_contents'],\n",
    "    'B': conflict['b_contents'],\n",
    "    'base': conflict['base_contents']\n",
    "}\n",
    "data = extract_feature(conflict)\n",
    "sample = [        \n",
    "    data['a_keyword_1'], \n",
    "    data['b_keyword_1'],\n",
    "    data['a_keyword_2'],\n",
    "    data['b_keyword_2'],\n",
    "    data['a_exist'],\n",
    "    data['b_exist'],\n",
    "    data['base_exist'],\n",
    "    data['a_edit_type'],\n",
    "    data['b_edit_type'],\n",
    "    data['ab_edit_type'],]\n",
    "clf.predict([sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\compiler\\anaconda\\envs\\skl\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tree.pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                     feature_names=vec.get_feature_names(),  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True,\n",
    "                     max_depth=5)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render('tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpype\n",
    "import os\n",
    "\n",
    "jvmPath = jpype.getDefaultJVMPath()\n",
    "jarPath = os.path.join(os.path.abspath('G:/project/java/ASTExtract/out/artifacts/ASTExtract_jar/ASTExtract.jar'))\n",
    "jpype.startJVM(jvmPath, '-ea', '-Djava.class.path=%s' % (jarPath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpype.shutdownJVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "javaClass = jpype.JClass('nju.merge.ASTExtractor')\n",
    "javaInstance = javaClass()\n",
    "[a, b] = javaInstance.call('54_a.java', 94, 105)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regex = '[a-z|A-Z|_][a-z|A-Z|_|0-9]*'\n",
    "s = 'fweaf_fewf_ffe'\n",
    "if re.fullmatch(regex, s):\n",
    "    print(1)\n",
    "else:\n",
    "    print(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boolean', 'byte', 'char', 'double', 'false', 'float', 'int', 'long', 'new', 'short', 'true', 'void', 'instanceof', 'break', 'case', 'catch', 'continue', 'default', 'do', 'else', 'for', 'if', 'reture', 'switch', 'try', 'while', 'finally', 'throw', 'this', 'super', 'abstract', 'fianal', 'native', 'private', 'protected', 'public', 'static', 'synchronized', 'transient', 'volatile', 'class', 'extend', 'implements', 'interface', 'ackage', 'import', 'throws']\n"
     ]
    }
   ],
   "source": [
    "a = 'boolean byte char double false float int long new short true void instanceof break case catch continue default do else for if reture switch try while finally throw this super abstract fianal native private protected public static synchronized transient volatile class extend implements interface ackage import throws'\n",
    "b = a.split(' ')\n",
    "# c = [ \"\\\"\" + word + \"\\\"\" for word in b]\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('skl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb08d773d2139837d102b682b0a2cd6e5593da88cae7c907e0cfed89f6f69e80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
